\section{Related Work}
\label{sec:relatedwork}

We categorize existing work related to our study into two main categories: speaker verification and speaker diarization.

\noindent \textbf{Speaker Diarization:} Speaker diarization has emerged as an increasingly important and dedicated domain of speech research. This technique has been used in broadcast news (BN) and conference meetings (CM) to identify the speaker according to their biometric features. The current state-of-the-art speaker diarization system fits into two categories: the bottom-up and the top-down methods. The bottom-up approaches \cite{Anguera2006Robust, Nguyen2009The, Nwe2012Speaker}, using hierarchical clustering (HC), training a number of clusters which aims at successively merging and reducing the number of clusters until only one remains for each speaker. In contrast, the top-down approaches \cite{Fredouille2006Technical, Bozonnet2010The, Fredouille2009The} first cluster the audio stream with a single speaker model and successively add new cluster to it until all the speakers are accounted for. Top-down approaches have performed well against the broader filed of other bottom-up entries. Our system needs the speaker diarization technique to identify the customer's audio, but telephone customer service is different from BN and CM. First, the above-mentioned clustering approaches cannot be applied in our TCS framework. That is because even we assume that the two clusters have been identified from the audio, we still do not know which cluster is customer's audio. Therefore, the binary classification approach has been applied in TCS. Second, the state-of-art speaker diarization system mainly uses the speaker's biometric features, such as audio waves, voice pitch, speaking style, etc, but our framework mainly use the speaker's content information, which is totally different from the former work. The reason to abandon biometric features is that we are difficult to identify some rules or models for these biometric features since these audio from various customers and services. On the other hand, the speaker's content can be used because of the difference speaking characters between customer and service.

\noindent \textbf{Speaker Verification:} So far, the GMM-UBM i-vector based model \cite{dehak2011front} is still the dominant model used in modern speaker verification systems. Recent years, with the development of deep neural network models in speech recognition, people start to explore using DNN in speaker verification framework. There are two dominant approaches that are the most widely adopted in research for combining deep neural network into speaker verification. One is to extract deep neural network bottleneck feature from SV feature (i.e. MFCC). As reported in \cite{yamada2013improvement}, one important factor that leads to superior performance improvement in distant-talking recognition is utilizing bottleneck feature to restrain channel-mismatch reverberant conditions. The other is to replace GMM posterior with DNN posterior during feature modeling, so called DNN-UBM \cite{Snyder2016Time, mclaren2015advances}. This method takes the advantage of deep neural network ability to directly model phonetic content, rather than an arbitrary acoustic space, and achieves a 50\% relative improvement compared to the traditional GMM-UBM method. DNN-UBM also well perform the first approach. Therefore, our SV framework uses the DNN-UBM approach, test with various kinds of DNN models to optimize the verification system performance.

% Introduction
\section{Introduction}

Voice recognition is the process of automatically recognizing a person from characteristic of voices. It can be classified into two folds, that is, speaker identification and speaker verification. Speaker identification is the process of determining a registered speaker from the given multiple utterances of various speakers, while speaker verification is the process of accepting or rejecting a person from the given personal utterance. Most of the applicable services in which banking system, financial business and security control use of voice to confirm the identity of a speaker for verification purpose. For example, in Ping An Group Inc., insurance department utilizes voice recognition technique within phone conversation between customers and client services to identify their identification, for relevant recommendation (i.e. credit card) purpose.

The framework of many voice recognition applications in use is a GMM-based i-vector system. It can be decomposed into four sequential stages: the feature extraction, the collection of sufficient statistics, the extraction of i-vectors and a scoring criterion backend. The feature extraction is a process converts the speech waveform into characteristic parameter, which retains useful speaker information from given speech signal and filters unwanted information such as noise. Parameters like Mel-Frequency Cepstrum Coefficient (MFCC), Linear Predictive Cepstral Coefficient (LPCC) and perceptual linear prediction (PLP) are often used in feature extraction stage, follow by voice activity detection (VAD). The collection of sufficient statistics is a process to calculate the zero-order, first-order, second-order Baum-Welch statistics from a sequence of feature vector from the first stage. These statistics are highly dimensional, which is generated from a large GMM, called Universal Background Model (UBM). The extraction of i-vectors in the third stage is a technique that converts the high dimensional statistics into a single low dimension feature vector, which carries only the discriminative characteristic information apart from the other speakers. Once i-vectors are extracted, a scoring criterion backend is used to make decision that whether accept or reject the person as the request identity. There are three commonly used scoring criterions for voice recognition, cosine distance similarity, linear discriminant analysis (LDA) and probabilistic linear discriminant analysis (PLDA).

The current system in Ping An voice recognition uses the GMM-based i-vector framework. Although it has achieved great success in some real-world applications (e.g., Happy Pingan APP, Knowlege  Bird ), there are two essential problems which decrease the system performance when bring it into some of our industrial production environment:

1.Co-channel speech problem the current system used in Ping An voice recognition task is required single track audio which is limited to some phone-call platforms. For co-channel speech, a tentative method is to extract customer¡¯s first utterance but its performance is poor.
2.Unsupervised GMM-based framework is conceptually an unsupervised way to discriminate speakers from given speech utterance. Specifically, the UBM is trained to cluster MFCCs into unsupervised clusters. This fact decreases the recognition performance when two speakers pronounce the same phone from the relative point (a supervised tied tri-phone state).

Notice that the longer utterance we send to the voice recognition system; the better identification performance we can get. We then manage to solve the above problems by utilizing DNN-based i-vector framework with a carefully designed diarization front-end built from automatic speech recognition (ASR) and natural language process (NLP) techniques, which helps to to find and concentrate customer¡¯s audio segments from co-channel speech via short text classification method. The deep neural network model we used for our system is a highway long short-term memory recurrent neural network model (Highway LSTM-RNN), which is used for speech recognition.

The rest of the paper is organized as follows: In Section \ref{sec:background} we introduce the background of main parts of typical speaker verification system and the DNN-UBM framework. In Section \ref{sec:algorithm} we describe the HLSTM-UBM model that we used for our voice recognition system and diarization front-end for managing co-channel speech. We summarize the experiment setup and report experiment results in Section \ref{sec:experiment}, conclusions are in Section \ref{sec:conclusion}.


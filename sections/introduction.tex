\section{Introduction}

Speaker Verification (SV), also called voice recognition, is the process of accepting or rejecting a person from the given personal utterance. Most of the applicable services in which banking system, financial business and security control use of voice to confirm the identity of a speaker for verification purpose. For example, Ping An insurance department utilizes Speaker Verification technique within phone conversation between customers and client services to authenticate their identification.

The current system in Ping An speaker verification uses GMM-based i-vector framework. Although it has achieved great success in some real-world applications (e.g., Happy Ping An APP \footnote{\url{http://tech.Pingan.com/product/sass_b_happy.shtml}}, Ping An Zhi Bird APP \footnote{\url{http://www.zhi-niao.com/}},) this technique has not been widely used in Ping An TCS (i.e. 95511) system.

There are three main problems in current SV model:

\begin{itemize}
\item Co-channel speech: the current system used in Ping An SV task requires single track audio which is limited to certain situations. For instance, the Ping An telephone service platform only records co-channel speech. The SV accuracy for these mix-audio with customer and service are extremely low (error ratio is more than 64\%.) Some tentative methods have been tried for handling co-channel speech, i.e. since at the beginning client service always says the same sentence (e.g., ``Hello, May I help you?",) we tried to extract customer¡¯s first utterance speech segments for verification. However, since the first utterance of customers are usually quite short (the average length is 4.4s, with 8.3 words,) the accuracy is still low (error ratio is about 13.2\%.) Therefore, how to extract the clean and long customer voice segments is a vital problem in this paper.

\item Ping An TCS requires a very short response time (less than 1s) for speaker recognition. The quicker to identify the user's information, the better services Ping An service can provide to customer.

\item The high accuracy SV algorithm is always expected in Ping An TCS.

\end{itemize}

To solve the above problems, we developed a SV system with customer/service identification front-end to extract customer speech segments from the co-channel audio data. Specifically, the system first uses automatic speech recognition (ASR) technique to transcribe mix-audio to text. Then, applies text classification approach to assign the customer label to these text. In the end, according to the text content and related time stamps (from ASR result,) the identification front-end can easily concatenate these customer's homogenous audio segments together.

For the high accuracy aspect, it is known that the current unsupervised GMM-based framework is conceptually an unsupervised way to discriminate speakers from given speech utterance. Specifically, the UBM is trained to cluster MFCCs into unsupervised clusters \cite{Mclaren2016On}. This fact decreases the verification performance when two speakers pronounce the same phone from the relative point (a supervised tied tri-phone state.) Therefore we propose to utilize a HLSTM-based i-vector framework instead of the GMM-based framework.


\noindent \textbf{Contributions:} The contributions of this paper are:
\begin{itemize}

\item In this paper, we discuss the co-channel problem for current telephone customer service. We argue that why current single channel SV approach cannot be directly used in TCS speaker recognition task.

\item We present a novel SV framework for this co-channel TCS. Apart from speaker's voice biometrics, the content of speaker's dialogue has also been used for identification. The long and clean customer's voice has been extracted from the the co-channel TCS. We also analyze the characters of customer service's dialogs. More accurate, efficient and scalable short text classification has been apply in our framework.

\item Extensive experimental analysis is performed on multiple, diverse data sets to show how the proposed algorithm provide more accurate and efficient results than other approaches. Meanwhile, this SV framework has been used in Ping An TCS.

\end{itemize}

\noindent The rest of the paper is organized as follows: In Section \ref{sec:relatedwork} we introduce the related work. In Section \ref{sec:algorithm} we describe the diarization front-end for managing co-channel speech and the HLSTM-UBM model that we used for our speaker recognition system. We summarize the experiment setup and report experiment results in Section \ref{sec:experiment} and conclusions are in Section \ref{sec:conclusion}.


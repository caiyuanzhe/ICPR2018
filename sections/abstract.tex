\begin{abstract}
 Speaker verification (SV) becomes ubiquitous, and are widely used in security login, telephone banking. The SV technique requires single-channel with each speaker, but currently the Ping An telephone customer service (TCS) platform only records co-channel speech in which customer and service's voices are mixed together. Directly using the mixed voice will receive a very low accuracy in SV. In this paper, we propose a new framework to manage this co-channel problem. We first transcribe the mixed audio to the set of short texts with time stamp by automatic speech recognition (ASR), then customer's short texts are identified by the proposed short text classification method. In the end, the customer's audio can be easily extracted and concatenated together. Meanwhile, to improve the SV accuracy, a highway long short-term memory recurrent neural network model (HLSTM) \cite{Zhang2016Highway} is incorporated in our SV subsystem. We found the HLSTM-UBM well performed than other deep neural network based UBM frameworks with comprehensive comparison in response time (less than 600ms) and accuracy (15\% relative improvement from GMM-UBM baseline), which can be adapted in real world telephone customer service.

\end{abstract}

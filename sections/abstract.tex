\begin{abstract}
 Speaker verification (SV) is the identification of a person from biometrics characteristics of voices (e.g., speech waves, voice pitch, speaking style, etc.) SV technique become ubiquitous, and are widely used in the various areas (e.g., mobile apps login, telephone banking, etc.) Hence, it would be beneficial if Ping An telephone customer service (TCS) can provide the personalized high quality service to the customer with this SV identification. For example, Ping An TCS are able to recommend the most related credit card, deposit plan, or insurance plan to the customer based on their history records. This paper addresses the problem of applying the more accuracy and efficient SV technique in real world telephone customer service.

 Current SV technique requires single-channel speech, but TCS records co-channel speech which means customer and service's voices are mixed together. Directly using the mixed voice will receive a very low accuracy. Hance, we propose a SV framework for this co-channel speech. We first transcribe customer's audio to the set of short texts with the time stamp by automatic speech recognition (ASR), and then customer's short texts are identified by our proposed short text classification approach. In the end, the customer's audio can be easily extracted and concatenated together. Meanwhile, to improve the SV accuracy, a highway long short-term memory recurrent neural network model (HLSTM) \cite{Zhang2016Highway} are used for automatic speech recognition. The use of a HLSTM-UBM framework in the speaker verification pipeline is attractive as it can integrate phonetic information to help us to discriminate between speakers even in text-independent speaker verification task and show promising results. We present our framework along with extensive experimental analysis that indicates superiority of our approach as compared to other methods.
\end{abstract}
